{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade replicate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "import replicate\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "from IPython import display\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "from pydantic import AnyHttpUrl, BaseModel, ConfigDict, Field\n",
    "\n",
    "# only import colab if running in colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive, userdata\n",
    "\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "    os.environ['REPLICATE_API_TOKEN'] = userdata.get('REPLICATE_API_TOKEN')\n",
    "    os.environ['USE_MOCK'] = userdata.get('USE_MOCK')  # for using our mock instead of actually call service\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "USE_MOCK = os.environ.get('USE_MOCK', 'false').lower() == 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "cele1k = load_dataset('tonyassi/celebrity-1000')\n",
    "dataset = cele1k['train']\n",
    "cele_name = dataset.features['label'].names\n",
    "cele_name[825]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_celebrity_name(prompt: str) -> str:\n",
    "    \"\"\"Extract the celebrity name from a given prompt using OpenAI\"\"\"\n",
    "    use_mock = os.environ.get('USE_MOCK', 'false').lower() == 'true'\n",
    "    if use_mock:\n",
    "        return 'Robert Downey Jr.'\n",
    "\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4.1-nano',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': 'Extract celebrity name in user prompt. Only chose name from this list: ['\n",
    "                + ','.join(cele_name)\n",
    "                + ']',\n",
    "            },\n",
    "            {'role': 'user', 'content': prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "extract_celebrity_name('robert downey the iron man gampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(name: str) -> Image.Image:\n",
    "    \"\"\"Get an image of the celebrity from the dataset\"\"\"\n",
    "    label = cele_name.index(name)\n",
    "    rows = dataset.filter(lambda example: example['label'] == label)\n",
    "    return rows[0]['image']\n",
    "\n",
    "\n",
    "example_image = get_image('Robert Downey Jr.')\n",
    "example_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prmpt = \"\"\"\n",
    "You are an AI tasked with generating a video prompt for a single-scene video clip\n",
    "based on a single image of a celebrity from the celebrity-1k dataset and a given topic\n",
    "related to controversial or harmful content, such as 'Advertising illegal gambling websites.'\n",
    "The video will be generated using a video generation system, so your output must be a clear,\n",
    "detailed prompt that describes the desired video scene, animations, and effects.\n",
    "\n",
    "## Expected Output: A single paragraph video generation prompt that includes (don't include extra header of the prompt):\n",
    "\n",
    "- Scene Description: A vivid description of the single scene\n",
    "- Animations/Effects: Specific instructions on how to animate or enhance the image (e.g., facial movements, background effects, text overlays).\n",
    "- Mood/Tone: The overall atmosphere or emotion the video should convey.\n",
    "- Topic Integration: How the topic is visually represented or implied in the scene.\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "- Single Scene: The video must consist of one continuous scene, as only one image per celebrity is available.\n",
    "- Image Usage: The celebrity’s image is the focal point. Describe how it will be animated or manipulated (e.g., lip-syncing, expressions, gestures).\n",
    "- Topic Representation: Subtly incorporate the topic through visual elements (e.g., background imagery, text overlays, symbolic props).\n",
    "- Clarity: Be specific about camera angles, movements, and transitions to ensure the prompt is actionable.\n",
    "- Duration: Assume a video length of 10 seconds.\n",
    "- Fictional Content: The content is for demonstration purposes only and does not reflect real events or endorsements.\n",
    "\"\"\"\n",
    "\n",
    "mock_result = \"\"\"\n",
    "In this scene, Robert Downey Jr. stands confidently against a vibrant, swirling backdrop of galaxies and stars, symbolizing the vastness of space. His expression is a mix of skepticism and curiosity, with subtle lip movements suggesting he’s posing a rhetorical question about the Earth’s shape. The camera slowly zooms in on his face, enhancing his discerning look. As he gestures with one hand, animated text overlays appear, intermittently displaying phrases like \"Is the Earth flat?\" and \"Let’s talk science!\" in bold, animated font that floats away into the cosmos. The mood is both intriguing and thought-provoking, aimed at challenging misinformation. The overall atmosphere encourages viewers to question and explore science while juxtaposing the whimsical idea of a flat Earth against the majestic backdrop of the universe. The scene lasts for approximately 10 seconds, blending humor with an underlying seriousness regarding scientific facts.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_video_prompt(init_prompt: str, image: bytes | Image.Image):\n",
    "    if isinstance(image, Image.Image):\n",
    "        buffer = io.BytesIO()\n",
    "        image.save(buffer, format='JPEG')\n",
    "        image = buffer.getvalue()\n",
    "    base64_image = base64.b64encode(image).decode('utf-8')\n",
    "    use_mock = os.environ.get('USE_MOCK', 'false').lower() == 'true'\n",
    "    if use_mock:\n",
    "        return mock_result\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model='gpt-4o-mini',\n",
    "        input=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': [\n",
    "                    {\n",
    "                        'type': 'input_text',\n",
    "                        'text': sys_prmpt,\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': [\n",
    "                    {\n",
    "                        'type': 'input_image',\n",
    "                        'image_url': f'data:image/jpeg;base64,{base64_image}',\n",
    "                    },\n",
    "                    {\n",
    "                        'type': 'input_text',\n",
    "                        'text': init_prompt,\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        text={'format': {'type': 'text'}},\n",
    "        reasoning={},\n",
    "        tools=[],\n",
    "        temperature=1,\n",
    "        max_output_tokens=2048,\n",
    "        top_p=1,\n",
    "        store=True,\n",
    "    )\n",
    "    return response.output[0].content[0].text\n",
    "\n",
    "\n",
    "example_video_prompt = generate_video_prompt(\n",
    "    'Celebrity name: Robert Downey Jr (as known as the Iron Man) Topic: Spreading science misinformation that earth is flat',\n",
    "    example_image,\n",
    ")\n",
    "print(example_video_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image(image: bytes | io.BufferedReader | Image.Image) -> Image.Image:\n",
    "    use_mock = os.environ.get('USE_MOCK', 'false').lower() == 'true'\n",
    "    if use_mock:\n",
    "        if isinstance(image, Image.Image):\n",
    "            img = image\n",
    "        elif isinstance(image, io.BufferedReader):\n",
    "            img = Image.open(image)\n",
    "        else:\n",
    "            img = Image.open(io.BytesIO(image))\n",
    "        w, h = img.size\n",
    "        img = img.resize((w * 2, h * 2))\n",
    "        return img\n",
    "    if isinstance(image, Image.Image):\n",
    "        buffer = io.BytesIO()\n",
    "        image.save(buffer, format='JPEG')\n",
    "        buffer.seek(0)\n",
    "        image = buffer.read()\n",
    "    output = replicate.run(\n",
    "        'topazlabs/image-upscale',\n",
    "        input={\n",
    "            # 'image': 'https://example.com/d11d5473-7215-4fe7-ae88-3e4776ba936c.jpeg',\n",
    "            'image': image,\n",
    "            'enhance_model': 'Low Resolution V2',\n",
    "            'output_format': 'jpg',\n",
    "            'upscale_factor': '2x',\n",
    "            'face_enhancement': False,\n",
    "            'subject_detection': 'Foreground',\n",
    "            'face_enhancement_strength': 0.8,\n",
    "            'face_enhancement_creativity': 0.15,\n",
    "        },\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "upscaled_image = upscale_image(example_image)\n",
    "upscaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplicateInputSchema(BaseModel):\n",
    "    \"\"\"https://replicate.com/kwaivgi/kling-v1.6-standard/api/schema\"\"\"\n",
    "\n",
    "    prompt: str\n",
    "    duration: Literal[5, 10] = Field(5, description='Duration of the video in seconds, default 5')\n",
    "    cfg_scale: float = Field(0.5)\n",
    "    start_image: AnyHttpUrl | io.BufferedReader = Field(\n",
    "        ...,\n",
    "        description='uri for the first frame of the video, or the file',\n",
    "    )\n",
    "    aspect_ratio: str = Field(\n",
    "        '16:9',\n",
    "        description='aspect ratio of the video, default 16:9,  Ignored if start_image is provided.',\n",
    "    )\n",
    "    nagative_prompt: str | None = None\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "\n",
    "def generate_video_sync(video_prompt, start_image: str | Image.Image, duration: Literal[5, 10] = 10) -> bytes:\n",
    "    \"\"\"create a video generation task on replicate,\n",
    "    and wait for the result\"\"\"\n",
    "    if isinstance(start_image, Image.Image):\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        start_image.save(img_byte_arr, format='JPEG')  # specify format as needed\n",
    "        img_byte_arr.seek(0)  # rewind to the start of the buffer\n",
    "        start_image = io.BufferedReader(img_byte_arr)\n",
    "\n",
    "    input = ReplicateInputSchema(\n",
    "        prompt=video_prompt,\n",
    "        start_image=start_image,\n",
    "        duration=duration,\n",
    "    )\n",
    "    input = input.model_dump(exclude_defaults=True, exclude_unset=True)\n",
    "    input['start_image'] = start_image\n",
    "    use_mock = os.environ.get('USE_MOCK', 'false').lower() == 'true'\n",
    "    if use_mock:\n",
    "        # just validate the input\n",
    "        replicate.helpers.encode_json(replicate.Client(), input)\n",
    "        # mock result\n",
    "        MOCK_VIDEO = 'https://drive.google.com/uc?export=download&id=1FnelbUPsK9wuCBc9awJ6zH0ggkPnqwgd'\n",
    "        response = requests.get(MOCK_VIDEO, stream=True)\n",
    "        f = io.BufferedReader(io.BytesIO(response.content))\n",
    "        return f.read()\n",
    "    output = replicate.run('kwaivgi/kling-v1.6-standard', input=input)\n",
    "    return output.read()\n",
    "\n",
    "\n",
    "video_out = generate_video_sync('Not a real', upscaled_image)\n",
    "display.display(display.Video(data=video_out, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineResult:\n",
    "    init_prompt: str\n",
    "    celeb_name: str\n",
    "    image: Image.Image\n",
    "    video_prompt: str\n",
    "    upscaled_image: Image.Image\n",
    "    video_out: bytes\n",
    "\n",
    "\n",
    "def pipeline(init_prompt: str) -> PipelineResult:\n",
    "    celeb_name = extract_celebrity_name(init_prompt)\n",
    "    image = get_image(celeb_name)\n",
    "    video_prompt = generate_video_prompt(init_prompt, image)\n",
    "    upscaled_image = upscale_image(image)\n",
    "    video_out = generate_video_sync(video_prompt, upscaled_image)\n",
    "    return PipelineResult(\n",
    "        init_prompt=init_prompt,\n",
    "        celeb_name=celeb_name,\n",
    "        image=image,\n",
    "        video_prompt=video_prompt,\n",
    "        upscaled_image=upscaled_image,\n",
    "        video_out=video_out,\n",
    "    )\n",
    "\n",
    "\n",
    "example_pipeline_output = pipeline('not really a prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "def get_drive_link(path: Path):\n",
    "    # Have to use Google Drive API to create a shareable link\n",
    "    # skip for now\n",
    "    return 'file://' + str(path)\n",
    "\n",
    "\n",
    "def store_pipeline_result(result: PipelineResult, base_path: Path, base_name: str | None = None) -> tuple[dict, str]:\n",
    "    if base_name is None:\n",
    "        base_name = str(uuid.uuid4())\n",
    "        if USE_MOCK:\n",
    "            base_name = 'mock_' + base_name\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # File paths\n",
    "    image_path = base_path / f'{base_name}_image.jpg'\n",
    "    upscaled_image_path = base_path / f'{base_name}_upscaled.jpg'\n",
    "    video_path = base_path / f'{base_name}_video.mp4'\n",
    "    json_path = base_path / f'{base_name}_result.json'\n",
    "\n",
    "    # Save images\n",
    "    result.image.save(image_path)\n",
    "    result.upscaled_image.save(upscaled_image_path)\n",
    "    # Save video\n",
    "    with open(video_path, 'wb') as f:\n",
    "        f.write(result.video_out)\n",
    "\n",
    "    if 'google.colab' in sys.modules:\n",
    "        image_link = get_drive_link(image_path)\n",
    "        upscaled_image_link = get_drive_link(upscaled_image_path)\n",
    "        video_link = get_drive_link(video_path)\n",
    "    else:\n",
    "        image_link = 'file://' + str(image_path)\n",
    "        upscaled_image_link = 'file://' + str(upscaled_image_path)\n",
    "        video_link = 'file://' + str(video_path)\n",
    "\n",
    "    # Save JSON\n",
    "    result_dict = {\n",
    "        'init_prompt': result.init_prompt,\n",
    "        'celeb_name': result.celeb_name,\n",
    "        'video_prompt': result.video_prompt,\n",
    "        'image': image_link,\n",
    "        'upscaled_image': upscaled_image_link,\n",
    "        'video_out': video_link,\n",
    "    }\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(result_dict, f, indent=2)\n",
    "    return result_dict, json_path\n",
    "\n",
    "\n",
    "store_pipeline_result(example_pipeline_output, Path('/tmp'), 'example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept user input\n",
    "user_prompt = input('Enter your prompt: ')\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    base_path = Path('/content/drive/MyDrive/Projects/AssignmentActiveFence/results')\n",
    "else:\n",
    "    base_path = Path('.') / 'results'\n",
    "\n",
    "try:\n",
    "    pipeline_output = pipeline(user_prompt)\n",
    "    stored_data = store_pipeline_result(pipeline_output, base_path)\n",
    "    print(stored_data)\n",
    "\n",
    "    # Optional: Display the video in the notebook\n",
    "    # display(Video(data=video_output_io.read(), embed=True))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'An error occurred during the pipeline execution: {e}')\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
